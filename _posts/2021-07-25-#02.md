# 02_From Model to Production

## モデルから実運用へ

熊検出器の構築  

本では、まず自分のプロジェクトをもつことだといっている。  
自分だったらなんだろう。  
犬の表情や鳴き声から、感情がわかるとかどうか？
本では、完璧なデータを準備するのに時間をかけずに、とりあえず開始して繰り返してみろと言っている。  
なる。  

## ディープラーニングの現状

### コンピュータビジョン
物体認識、物体検出、ピクセルに映っているものを分類するセグメンテーションなど。  
* 注意点
  * 訓練データに白黒画像がなければ、白黒画像の識別は出来ない。手書き画像が含まれていなければその識別はうまくできない。  
（ドメイン外のデータ） 
  * 画像のラベル付けに時間・コストがかかる。→データ水増し(data augmentation)
### テキスト（自然言語処理）
文書をさまざまなカテゴリーに分類、文脈に応じたテキスト生成
* 注意点
  * 必ず正しい生成は出来ない
  * 例えばsnsのレスポンスを大規模に精鋭出来てしまう
### テキストと画像の組み合わせ
ディープラーニングではテキストと画像を一つのモデルとして扱うことが可能。  
### 推薦システム
* 注意点
  * ユーザがすでに知っている製品を推薦することがある

## ドライブトレインアプローチ
役立つモデルを作るための手法。
* 目的を定義：どのような結果を達成したいか
* レバー：どのような入力を制御できるか：取り得るアクションはなにか
* データ：どのような入力を収集できるか
* モデル：どのようにレバーが目的に影響するか

例えばgoogleの検索エンジンなら
* 目的を定義：もっとも関連がありそうな検索結果を表示する
* レバー：検索結果にランキングをつける
* データ：どのぺーじからどのページに繋がっているのか暗黙の情報
* モデル：

例えば推薦システムなら
* 目的を定義：買わなかったようなものを顧客に買わせる
* レバー：推薦のランキング
* データ：さまざまな推薦をさまざまな顧客に提示した結果のデータ
* モデル：推薦を見た場合とみなかった場合の２つのモデル→２つの確率の差が有用性を表す

## 熊検出器を作ってみよう
いやいや、この章が何度もやってみたのですが、なかなか動かない。  
今回ようやく動いたのですが、なぜ今回は動いたのか実はよくわからない。
これは３種類のクマを識別する。grizzle bear, black bear , teddy bearの３種類。  
インターネット上の画像をMicrosoftのBing　Image Searchを使って画像をダウンロードして識別器を作る。  

### まずMSのアカウント作ってBing Search APIを作る
そうなんだ、まずここで詰まった。本では詳細が書かれていない。
[これを参照するとよかった。](https://medium.datadriveninvestor.com/fastai-course-chapter-2-on-windows-6ee427c1d2d7)  
ま、簡単に書くとMSのAzureでアカウント作って、Bing search APIを作るということだ。  

![](/images/2021-08-01_1.jpg "ms1")
![](/images/2021-08-01_2.jpg "ms2")  
  
そして、以下の手順でkeyを取得するのだ。  
  
![](/images/2021-08-01_3.jpg "ms3")  

ここに来るまでに時間がかかってしまった。  

### jupyterノートブックへ
でノートブックにいき、先ほどのkeyを以下XXXに書き込む。  

`key = os.environ.get('AZURE_SEARCH_KEY', XXX)`   

次に以下コマンドで画像のURLが取得できるとのこと。  
`results = search_images_bing(key, 'grizzly bear')`  
`ims = results.attrgot('contentUrl')`  

本当にURLが取得出来ているのかわからなかったので、以下コマンドを追記してみる。  
`print("results[0]:", results[0], "\n")`  
`print("ims[0]:", ims[0], "\n")`  

そうすると、取得できているのがわかった。   
![](/images/2021-08-01_4.jpg "ms4")   
  
その後、以下コマンドを実行するのだが、画像が置き換わって表示されない。なんでだ？   
私のつたない知識では、imsに新しいURLが入っているのだから、画像も変わるのでは？  
`dest = 'images/grizzly.jpg'`  
`download_url(ims[0], dest)`  
![](/images/2021-08-01_5.jpg "grizzly1")     
  
jupyter notobook の imageフォルダーに画像がはいるのでは？  
たしかにgrizzlyの画像が入っているのだが、本に表示されている画像で、先ほど取得したURLの画像ではない。  
もしかしたら、すでにある画像は置き換わらないのでは？images/grizzly.jpgの部分をgrizzly2.jpgとしてみる。  
おお！ようやく新しい熊の写真になったぞ。
![](/images/2021-08-01_6.jpg "grizzly2")   
  
で、fastaiのdownload_imagesを使ってダウンロードを実施しろとな。

```python
bear_types = 'grizzly','black','teddy'
path = Path('bears')
```
```python
if not path.exists():
    path.mkdir()
    for o in bear_types:
        dest = (path/o)
        dest.mkdir(exist_ok=True)
        results = search_images_bing(key, f'{o} bear')
        download_images(dest, urls=results.attrgot('contentUrl'))
```
そうすると、jupytherでのbearsの下にblack,grizzly,teddyフォルダーが作成され、画像がはいっているがな。  
![](/images/2021-08-01_7.jpg "bear")  
  
画像が使えるものなのかをチェック
```python
failed = verify_images(fns)
failed
```
で、使えない画像を削除するためにunlinkを使う。
```python
def verify_images(fns):
    "Find images in `fns` that can't be opened"
    return L(fns[i] for i,o in enumerate(fns.map(verify_image)) if not o)

failed = verify_images(fns)
failed
```
  
  
本ではここで、モデルを訓練する際、用いたデータだけで訓練するのでバイアスがかかることを注意するようにと書かれている。  
例えば、Bing Image Searchでhealty skinを検索すると以下の様な画像が入手できる。
![](/images/healty_skin.jpg "healty skin")   

でも上記画像でモデルを訓練すると「健康な肌」ではなく「顔を触っている若い白人の女性」検出器ができてしまう。

### ダウンロードした画像をモデルの学習に適した形に組み上げる～データからDataLoadersへ
DataLoadersとは与えられたDataLoaderオブジェクトをtrainとvalidとして返すためのクラスとな。  
なんだそれ。  

```python
bears = DataBlock(
    blocks=(ImageBlock, CategoryBlock), 
    get_items=get_image_files, 
    splitter=RandomSplitter(valid_pct=0.2, seed=42),
    get_y=parent_label,
    item_tfms=Resize(128))
 ```
   
なんかよくわからん。  
まず、独立変数とお従属変数のタイプを指定しているらしい。 
独立変数とは予測に用いる変数(画像のセット)で、従属変数は予測のターゲットになる変数(画像のカテゴリ＝クマの種類)とな。  
でも、どうやってクマの種類を教えているのだ？？   
  
以下の関数はパスを受け取り、そこにある画像を取得してリストとして返すとのこと。  
```python
get_items=get_image_files, 
```
  
で、以下でテストセットと検証セットをランダムに分割するそうだ。  
```python
splitter=RandomSplitter(valid_pct=0.2, seed=42)
```
  
と、ここで独立変数をx、従属変数をyと書くと出てくる。で従属変数にデータセットのラベルを作りだすための関数がでてくる。  
```python
get_y=parent_label
```  
  
上記関数はfastaiで提供されており、ファイルが格納されているフォルダ名をそのままラベルとするらしい。  
なるほど、理解した。  
  
ダウンロードした画像は当然ながらサイズがまちまちだ。ただ、それだとディープラーニングでは問題となる。  
またモデルに画像を与えるには何枚かまとめて与える。これをミニバッチと呼ぶとな。  
何枚かの画像を一つの大きな配列（テンソルと呼ぶ）にまとめてモデルに与える与えるが、それには画像がすべて同じサイズでないといけないらしい。  
  
個々のアイテムに対して実行されるコードをアイテム変換と呼ぶらしい。  
でそのアイテム変換でリサイズ変換をする。なるほど。  
```python
item_tfms=Resize(128)
```  

そしてデータソースをfastaiに教える。
```python
dls = bears.dataloaders(path)
```  

で、DataLoaderには検証セットと訓練セットが格納されている。  
ただし、デフォルトでは画像の縦または横をいっぱいに使ってクロップ（切り抜き）し、指定したサイズの正方形にしてしまう。  
そうすると重要な細部が失われてしまう可能性がある。


### モデルの訓練とそれを用いたデータクリーニング

```python
bears = bears.new(
    item_tfms=RandomResizedCrop(224, min_scale=0.5),
    batch_tfms=aug_transforms())
dls = bears.dataloaders(path)
```
どうやらaug_transformsでモデルを訓練しているとのこと。  
